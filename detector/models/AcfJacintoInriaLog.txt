---------------------------------------------------------------------------
Training stage 0
Sampled 1236 windows from 614 images.
Done sampling windows (time=28s).
Computing lambdas... done (time=15s).
Extracting features... done (time=5s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=5s).
Extracting features... done (time=11s).
Training AdaBoost: nWeak= 32 nFtrs=2560 pos=2472 neg=5000
 i=  16 alpha=0.353 err=0.330 loss=1.48e-01
 i=  32 alpha=0.375 err=0.321 loss=5.55e-02
Done training err=0.0101 fp=0.0114 fn=0.0089 (t=0.2s).
Done training stage 0 (time=65s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 256 images.
Done sampling windows (time=16s).
Extracting features... done (time=11s).
Training AdaBoost: nWeak=128 nFtrs=2560 pos=2472 neg=10000
 i=  16 alpha=0.250 err=0.378 loss=3.85e-01
 i=  32 alpha=0.237 err=0.383 loss=2.56e-01
 i=  48 alpha=0.178 err=0.412 loss=1.77e-01
 i=  64 alpha=0.204 err=0.399 loss=1.27e-01
 i=  80 alpha=0.195 err=0.404 loss=9.14e-02
 i=  96 alpha=0.172 err=0.415 loss=6.57e-02
 i= 112 alpha=0.196 err=0.403 loss=4.78e-02
 i= 128 alpha=0.222 err=0.391 loss=3.57e-02
Done training err=0.0019 fp=0.0034 fn=0.0004 (t=0.8s).
Done training stage 1 (time=28s).
---------------------------------------------------------------------------
Training stage 2
Sampled 5000 windows from 448 images.
Done sampling windows (time=22s).
Extracting features... done (time=11s).
Training AdaBoost: nWeak=512 nFtrs=2560 pos=2472 neg=10000
 i=  16 alpha=0.223 err=0.390 loss=4.89e-01
 i=  32 alpha=0.196 err=0.403 loss=3.44e-01
 i=  48 alpha=0.186 err=0.408 loss=2.66e-01
 i=  64 alpha=0.161 err=0.420 loss=2.05e-01
 i=  80 alpha=0.188 err=0.407 loss=1.62e-01
 i=  96 alpha=0.185 err=0.409 loss=1.28e-01
 i= 112 alpha=0.182 err=0.410 loss=9.98e-02
 i= 128 alpha=0.164 err=0.419 loss=7.97e-02
 i= 144 alpha=0.148 err=0.427 loss=6.55e-02
 i= 160 alpha=0.156 err=0.423 loss=5.30e-02
 i= 176 alpha=0.166 err=0.418 loss=4.33e-02
 i= 192 alpha=0.173 err=0.414 loss=3.56e-02
 i= 208 alpha=0.172 err=0.415 loss=2.89e-02
 i= 224 alpha=0.147 err=0.427 loss=2.37e-02
 i= 240 alpha=0.159 err=0.421 loss=1.92e-02
 i= 256 alpha=0.155 err=0.423 loss=1.58e-02
 i= 272 alpha=0.163 err=0.419 loss=1.30e-02
 i= 288 alpha=0.158 err=0.422 loss=1.06e-02
 i= 304 alpha=0.167 err=0.417 loss=8.61e-03
 i= 320 alpha=0.173 err=0.415 loss=7.05e-03
 i= 336 alpha=0.166 err=0.418 loss=5.80e-03
 i= 352 alpha=0.161 err=0.420 loss=4.83e-03
 i= 368 alpha=0.139 err=0.431 loss=4.05e-03
 i= 384 alpha=0.153 err=0.424 loss=3.32e-03
 i= 400 alpha=0.155 err=0.423 loss=2.75e-03
 i= 416 alpha=0.184 err=0.409 loss=2.26e-03
 i= 432 alpha=0.155 err=0.423 loss=1.86e-03
 i= 448 alpha=0.183 err=0.410 loss=1.53e-03
 i= 464 alpha=0.133 err=0.434 loss=1.27e-03
 i= 480 alpha=0.153 err=0.424 loss=1.06e-03
 i= 496 alpha=0.156 err=0.423 loss=8.74e-04
 i= 512 alpha=0.149 err=0.426 loss=7.20e-04
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=2.9s).
Done training stage 2 (time=36s).
---------------------------------------------------------------------------
Training stage 3
Sampled 5000 windows from 1216 images.
Done sampling windows (time=59s).
Extracting features... done (time=11s).
Training AdaBoost: nWeak=2048 nFtrs=2560 pos=2472 neg=10000
 i=  16 alpha=0.178 err=0.412 loss=5.94e-01
 i=  32 alpha=0.171 err=0.415 loss=4.74e-01
 i=  48 alpha=0.154 err=0.424 loss=3.86e-01
 i=  64 alpha=0.165 err=0.418 loss=3.21e-01
 i=  80 alpha=0.143 err=0.429 loss=2.71e-01
 i=  96 alpha=0.131 err=0.435 loss=2.31e-01
 i= 112 alpha=0.141 err=0.430 loss=1.96e-01
 i= 128 alpha=0.160 err=0.421 loss=1.69e-01
 i= 144 alpha=0.112 err=0.444 loss=1.45e-01
 i= 160 alpha=0.119 err=0.441 loss=1.23e-01
 i= 176 alpha=0.143 err=0.429 loss=1.07e-01
 i= 192 alpha=0.117 err=0.442 loss=9.22e-02
 i= 208 alpha=0.127 err=0.437 loss=7.95e-02
 i= 224 alpha=0.136 err=0.432 loss=6.82e-02
 i= 240 alpha=0.132 err=0.435 loss=5.91e-02
 i= 256 alpha=0.155 err=0.423 loss=5.08e-02
 i= 272 alpha=0.140 err=0.431 loss=4.41e-02
 i= 288 alpha=0.132 err=0.434 loss=3.87e-02
 i= 304 alpha=0.156 err=0.423 loss=3.34e-02
 i= 320 alpha=0.137 err=0.432 loss=2.91e-02
 i= 336 alpha=0.131 err=0.435 loss=2.54e-02
 i= 352 alpha=0.118 err=0.441 loss=2.21e-02
 i= 368 alpha=0.130 err=0.435 loss=1.91e-02
 i= 384 alpha=0.134 err=0.434 loss=1.66e-02
 i= 400 alpha=0.157 err=0.422 loss=1.46e-02
 i= 416 alpha=0.137 err=0.432 loss=1.25e-02
 i= 432 alpha=0.127 err=0.437 loss=1.09e-02
 i= 448 alpha=0.126 err=0.437 loss=9.46e-03
 i= 464 alpha=0.137 err=0.432 loss=8.17e-03
 i= 480 alpha=0.133 err=0.434 loss=7.09e-03
 i= 496 alpha=0.133 err=0.434 loss=6.06e-03
 i= 512 alpha=0.138 err=0.432 loss=5.20e-03
 i= 528 alpha=0.136 err=0.432 loss=4.53e-03
 i= 544 alpha=0.128 err=0.436 loss=3.92e-03
 i= 560 alpha=0.122 err=0.439 loss=3.45e-03
 i= 576 alpha=0.131 err=0.435 loss=3.00e-03
 i= 592 alpha=0.120 err=0.440 loss=2.62e-03
 i= 608 alpha=0.146 err=0.428 loss=2.25e-03
 i= 624 alpha=0.137 err=0.432 loss=1.97e-03
 i= 640 alpha=0.135 err=0.433 loss=1.71e-03
 i= 656 alpha=0.136 err=0.433 loss=1.49e-03
 i= 672 alpha=0.150 err=0.426 loss=1.29e-03
 i= 688 alpha=0.143 err=0.429 loss=1.12e-03
 i= 704 alpha=0.113 err=0.444 loss=9.80e-04
 i= 720 alpha=0.121 err=0.440 loss=8.47e-04
 i= 736 alpha=0.124 err=0.438 loss=7.40e-04
 i= 752 alpha=0.144 err=0.428 loss=6.50e-04
 i= 768 alpha=0.124 err=0.438 loss=5.63e-04
 i= 784 alpha=0.129 err=0.436 loss=4.96e-04
 i= 800 alpha=0.120 err=0.440 loss=4.35e-04
 i= 816 alpha=0.127 err=0.437 loss=3.77e-04
 i= 832 alpha=0.123 err=0.439 loss=3.29e-04
 i= 848 alpha=0.132 err=0.434 loss=2.86e-04
 i= 864 alpha=0.124 err=0.439 loss=2.51e-04
 i= 880 alpha=0.138 err=0.431 loss=2.19e-04
 i= 896 alpha=0.126 err=0.437 loss=1.91e-04
 i= 912 alpha=0.130 err=0.435 loss=1.66e-04
 i= 928 alpha=0.131 err=0.435 loss=1.44e-04
 i= 944 alpha=0.122 err=0.440 loss=1.26e-04
 i= 960 alpha=0.152 err=0.425 loss=1.09e-04
 i= 976 alpha=0.133 err=0.434 loss=9.50e-05
 i= 992 alpha=0.130 err=0.435 loss=8.33e-05
 i=1008 alpha=0.129 err=0.436 loss=7.23e-05
 i=1024 alpha=0.143 err=0.429 loss=6.31e-05
 i=1040 alpha=0.119 err=0.441 loss=5.52e-05
 i=1056 alpha=0.125 err=0.438 loss=4.84e-05
 i=1072 alpha=0.136 err=0.433 loss=4.19e-05
 i=1088 alpha=0.137 err=0.432 loss=3.67e-05
 i=1104 alpha=0.127 err=0.437 loss=3.16e-05
 i=1120 alpha=0.137 err=0.432 loss=2.74e-05
 i=1136 alpha=0.125 err=0.438 loss=2.38e-05
 i=1152 alpha=0.118 err=0.441 loss=2.09e-05
 i=1168 alpha=0.131 err=0.435 loss=1.81e-05
 i=1184 alpha=0.139 err=0.431 loss=1.57e-05
 i=1200 alpha=0.138 err=0.431 loss=1.37e-05
 i=1216 alpha=0.135 err=0.433 loss=1.20e-05
 i=1232 alpha=0.135 err=0.433 loss=1.05e-05
 i=1248 alpha=0.130 err=0.435 loss=9.21e-06
 i=1264 alpha=0.121 err=0.440 loss=8.07e-06
 i=1280 alpha=0.102 err=0.449 loss=7.04e-06
 i=1296 alpha=0.125 err=0.438 loss=6.21e-06
 i=1312 alpha=0.146 err=0.428 loss=5.41e-06
 i=1328 alpha=0.106 err=0.447 loss=4.75e-06
 i=1344 alpha=0.129 err=0.436 loss=4.17e-06
 i=1360 alpha=0.147 err=0.427 loss=3.64e-06
 i=1376 alpha=0.125 err=0.438 loss=3.19e-06
 i=1392 alpha=0.112 err=0.444 loss=2.80e-06
 i=1408 alpha=0.125 err=0.438 loss=2.43e-06
 i=1424 alpha=0.132 err=0.435 loss=2.15e-06
 i=1440 alpha=0.136 err=0.432 loss=1.88e-06
 i=1456 alpha=0.138 err=0.431 loss=1.65e-06
 i=1472 alpha=0.154 err=0.424 loss=1.44e-06
 i=1488 alpha=0.118 err=0.441 loss=1.26e-06
 i=1504 alpha=0.142 err=0.430 loss=1.10e-06
 i=1520 alpha=0.140 err=0.431 loss=9.57e-07
 i=1536 alpha=0.131 err=0.435 loss=8.27e-07
 i=1552 alpha=0.128 err=0.437 loss=7.22e-07
 i=1568 alpha=0.138 err=0.431 loss=6.34e-07
 i=1584 alpha=0.121 err=0.440 loss=5.58e-07
 i=1600 alpha=0.127 err=0.437 loss=4.88e-07
 i=1616 alpha=0.125 err=0.438 loss=4.27e-07
 i=1632 alpha=0.137 err=0.432 loss=3.74e-07
 i=1648 alpha=0.132 err=0.435 loss=3.26e-07
 i=1664 alpha=0.124 err=0.438 loss=2.89e-07
 i=1680 alpha=0.119 err=0.441 loss=2.52e-07
 i=1696 alpha=0.124 err=0.438 loss=2.21e-07
 i=1712 alpha=0.120 err=0.440 loss=1.94e-07
 i=1728 alpha=0.156 err=0.423 loss=1.68e-07
 i=1744 alpha=0.120 err=0.441 loss=1.46e-07
 i=1760 alpha=0.114 err=0.443 loss=1.28e-07
 i=1776 alpha=0.134 err=0.433 loss=1.12e-07
 i=1792 alpha=0.129 err=0.436 loss=9.83e-08
 i=1808 alpha=0.137 err=0.432 loss=8.64e-08
 i=1824 alpha=0.128 err=0.437 loss=7.55e-08
 i=1840 alpha=0.116 err=0.442 loss=6.64e-08
 i=1856 alpha=0.130 err=0.435 loss=5.81e-08
 i=1872 alpha=0.126 err=0.437 loss=5.06e-08
 i=1888 alpha=0.138 err=0.431 loss=4.46e-08
 i=1904 alpha=0.121 err=0.440 loss=3.92e-08
 i=1920 alpha=0.123 err=0.439 loss=3.46e-08
 i=1936 alpha=0.114 err=0.443 loss=3.04e-08
 i=1952 alpha=0.120 err=0.440 loss=2.67e-08
 i=1968 alpha=0.136 err=0.433 loss=2.32e-08
 i=1984 alpha=0.143 err=0.429 loss=2.02e-08
 i=2000 alpha=0.124 err=0.438 loss=1.78e-08
 i=2016 alpha=0.128 err=0.436 loss=1.57e-08
 i=2032 alpha=0.130 err=0.435 loss=1.37e-08
 i=2048 alpha=0.129 err=0.436 loss=1.20e-08
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=10.3s).
Done training stage 3 (time=81s).
---------------------------------------------------------------------------
Done training (time=210s).
